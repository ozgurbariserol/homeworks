{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3JXKnyaM+x1040LmG9Zn7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"iY-KEWNunRj1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"metadata":{"id":"PYEQ_lwFm4Bi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rootdir = '/metin-web'"],"metadata":{"id":"-MwVK3s3m5e6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr = []\n","\n","for subdir, dirs, files in os.walk(rootdir):\n","  sinif = subdir.replace(rootdir+\"/\",\"\")\n","  for file in files:\n","    with open(os.path.join(subdir, file),  encoding=\"windows-1254\", errors='ignore') as tweet:\n","      arr.append({\"tweet\":tweet.read(),\"Sınıf\":sinif})\n"," \n","    \n","df = pd.DataFrame(arr, columns = [\"tweet\", \"Sınıf\"])\n","\n","sentences_training = [doc for doc in df.iloc[:,0]]\n","classification_training = [doc for doc in df.iloc[:,1]]\n"],"metadata":{"id":"BzLXj8tzm7vv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","vectorizer = TfidfVectorizer(analyzer='word', lowercase = True,stop_words = ['Turkish'])\n","sen_train_vector = vectorizer.fit_transform(sentences_training)"],"metadata":{"id":"0jbwmSQEnDsm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QA4Ss5uGjLYE","executionInfo":{"status":"ok","timestamp":1676908341020,"user_tz":-180,"elapsed":70979,"user":{"displayName":"Özgür Barış EROL","userId":"11121518915371302585"}},"outputId":"410428b0-f58b-42ed-fe76-e5e762ea905f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['turkish'] not in stop_words.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["       turkcell        bu   de  güzel       bir  hayat  superonline\n","a0     0.060638  0.000000  0.0    0.0  0.000000    0.0     0.000000\n","a1     0.000000  0.000000  0.0    0.0  0.000000    0.0     0.000000\n","a2     0.102857  0.000000  0.0    0.0  0.000000    0.0     0.000000\n","a3     0.257130  0.000000  0.0    0.0  0.000000    0.0     0.000000\n","a4     0.000000  0.000000  0.0    0.0  0.000000    0.0     0.256131\n","...         ...       ...  ...    ...       ...    ...          ...\n","a2995  0.056015  0.000000  0.0    0.0  0.000000    0.0     0.000000\n","a2996  0.050318  0.103244  0.0    0.0  0.219411    0.0     0.000000\n","a2997  0.000000  0.000000  0.0    0.0  0.110278    0.0     0.000000\n","a2998  0.068645  0.000000  0.0    0.0  0.149665    0.0     0.000000\n","a2999  0.108382  0.000000  0.0    0.0  0.000000    0.0     0.000000\n","\n","[3000 rows x 7 columns]\n"]}],"source":["\n","clf = GaussianNB()\n","model = clf.fit(X=sen_train_vector.toarray(), y=classification_training)\n","\n","tf_idf = pd.DataFrame(sen_train_vector.todense())\n","tf_idf.columns = vectorizer.get_feature_names()\n","tfidf_matrix = tf_idf.T\n","tfidf_matrix.columns = ['a'+ str(i) for i in range(0, len(tf_idf))]\n","tfidf_matrix['count'] = tfidf_matrix.sum(axis=1)\n","\n","tfidf_matrix = tfidf_matrix.sort_values(by ='count', ascending=False)[:] \n","\n"," \n","print(tfidf_matrix.drop(columns=['count']).head(7).T) #### sutun cok fazla oldugundan ilk 7 kelimeyi yazdırdım"]}]}